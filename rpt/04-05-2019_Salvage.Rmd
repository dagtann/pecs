---
title: 2nd Report on Tillman Replication
date: 04/26/2019
output:
  pdf_document:
    includes:
      in_header: header.tex
---

\tableofcontents
\newpage

```{r, options_chunk, include=FALSE}
knitr::opts_chunk$set(
    cache = FALSE, eval = TRUE, echo = FALSE, fig.align = "center",
    fig.width = 12, fig.height = 8, warning = FALSE, message = FALSE
)
source("~/github/pecs/src/r/master.R")
tillman <- filter(tillman,
    !(country %in% c("Australia", "Canada", "Luxembourg")) # not in publication
)
```

\section{Trends in the data}

\subsection{What's the grand picture?}

```{r, detrendAnalysis, include = FALSE}
source(file.path(path_project, "src", "r", "salvage", "01_01_detrend_analysis.R"))
```

Turnout has been declining for decades. Starting in 1970, participation in general
elections decreased from an average
`r sprintf("%.2f", 100 * mean(tillman$turnout[tillman$year == 1970]))` per cent to
`r sprintf("%.2f", 100 * mean(tillman$turnout[tillman$year == 2011]))` per cent in
2011. The figure above shows the development for all democracies in the data. With
the exceptions of Belgium and Denmark turnout has declined across the board
although differences in speed, magnitude, and monotonicity of the decline
are appearent.

\begin{figure}[ht]
    \caption{Trends in Turnout}
    \includegraphics[width=\textwidth]{~/github/pecs/out/scatter_smoother_detrendTurnout.pdf}

    \textbf{Note}: Confidence envelope at the .95 level.
\end{figure}

Importantly, trends that parallel turnout plague Tillman's two key predictors:
the formation of pre-electoral coalitions and their voting percentage. The
figure below shows Z-standardized versions of the fixed-effect transformed
response and its two key predictors. Although developments may not always align
to 100 percent, e.g., Italy, cases like Germany, the Netherlands, Greece or
Denmark highlight the potential for confounding trends in Tillman's analysis
clear.

\begin{figure}[ht]
    \caption{Shared Trends in Treatments and Response}
    \includegraphics[width=\textwidth]{~/github/pecs/out/line_commonTrend_Pec1_Turnout.pdf}

    \small{\textbf{Note}: Rug plots indicate election years.}
\end{figure}

\newpage


## What do the detrended results look like?

Several options to detrend panel data are on the table.
\begin{enumerate}
    \item Indicator variables for observations can account for all apparent
        trends in the data. However, they reduce statistical power quite a bit.
    \item Reduced form trend models of observation time, e.g., polynomials or
        splines, are easily implemented, but quickly overfit the data
    \item Sophisticated error structures, e.g., AR(1), correct standard
        errors and p-values. Unfortunately, they ignore the biased effect
        estimate.
    \item A set of lagged responses removes any trend up to the cardinality of
        the set, but it will bias results if the trend is more complex than
        that.
    \item Substantive models of the trend in the outcome. However, if those
        models are to reduce confoundedness then they should yield leverage on
        the treatment(s) as well.
\end{enumerate}

Keeping in mind our paper's purpose -- a replication and data feature --,
options one and two strike as most promising. Table
\ref{tbl:DetrendedRegressionResults} replicates Tillman's entire analysis using
cubic base [splines](https://en.wikipedia.org/wiki/B-spline) with three
knots.\footnote{
    The last report already presented the dummy variable approach. Moreover,
    I have checked simpler trend formulations, i.e. polynomials up to third
    degree. The association between PEC and turnout always collapses, no matter
    what approach to detrending was taken.
}
The table reports panel robust standard errors, clustered by country. There are
three take-away messages.

```{r, results = "asis"}
texreg(fitted_models,
    digits = 2,
    override.se = lapply(bk_se, function(x){sqrt(diag(x))}),
    override.p = bk_pval,
    custom.coef.names = c("PEC", "Parties", "Disproportionality", "PR",
        "Plurality", "Closeness", "Economic Growth", "log(Income)", "Spline 1",
        "Spline 2", "Spline 3", "Spline 4",
        "PR $\\times$ Disproprtionality", "Plurality $\\times$ Closeness",
        "PEC $>$ 20\\%", "Vote PEC", "Small PEC", "Large PEC"
    ),
    reorder.coef = c(1, 15, 16, 17, 18, 2:14),
    caption = "Detrended Regression Results", caption.above = TRUE,
    label = "tbl:DetrendedRegressionResults"
)
```

\begin{enumerate}
    \item As before, the \textit{formation} of pre-electoral coalitions does
        not boost turnout once trends are taken into account. The estimated
        effect on PEC approaches zero and more sophisticated trend
        formulations will not substantively change this outcome: Shared trends
        confound Tillman's pivotal analysis.
    \item Interestingly, Models 2 through 4 imply that strong pre-electoral
        coalitions still boost turnout. According to Model 3, every additional
        vote percentage point which goes to PECS increases turnout by $0.027$
        percentage points. Moreover, Models 2 and 4 strongly suggest that this
        effect turns strong pre-electoral coalitions, i.e. PECs that account
        for at least 20 percent of the vote.

        However, voting results for PECs are downstream from turnout.
        Therefore, it is very likely that something else but time confounds
        these effects. Suspects range from institutions and party system
        polarization to observable properties of PECS, e.g. former cabinet
        status of its members or coalition type.
    \item Once the analysis has been detrended, many of the remaining
        regressors tend towards zero. At least, most of them do not flip sign.
        Consequently, not everything about Tillman's analysis is confounded by
        trends. There is something to be salvaged.
\end{enumerate}

\section{Refinement of institutional covariates}

To control for established, alternative influences on turnout (p. 731) Tillman's
analysis includes information on disproportionality, the effective number of
electoral parties (ENEP), the closeness of elections, and existence of proportional
respectively plurality tiers. Moreover, for reasons not entirely clear the
author includes two interaction terms: PR $\times$ disproportionality and
Plurality $\times$ closeness. Table \ref{tbl:UnivariateSummaryInstitutions} shows
univariate summaries.


```{r, results = "asis"}
institution_label <- paste(
    c("pr", "plurality", "disprop", "enep", "closeness"), "wi", sep ="_"
)
institution_location <- which(names(tillman) %in% institution_label)
names(institution_location) <- institution_label
mytbl <- apply(tillman[, institution_location], 2, summary)
colnames(mytbl) <- c("ENEP", "Disproprtionality", "PR", "Plurality", "Closeness")
stargazer::stargazer(mytbl, header = FALSE,
    title = "Summary of Demeaned Institutional Controls",
    label = "tbl:UnivariateSummaryInstitutions"
)
```

Note that the PR and plurality indicator variables basically do not vary
within countries. In fact, they are glued to $0$ in about $90$ percent of all
observations (`r sprintf("%.3f", apply(tillman[, c("pr_wi", "plurality_wi")],
2, function(x){mean(x == 0)}))`). Only France, Italy, Japan, and New Zealand
contribute variance, rendering their estimated effects on turnout particularly
volatile. Also, these indicators correlate quite strongly as do PR and
disproportionality (see the correlation matrix in Table
\ref{tbl:CorrelationInstitutions}). Finally, the codings strike me as
untrustworthy. For example, Japan has always had a plurality
component, but the data recognize that only from 1996 onward.
That same year, the Japanese electoral system went from SMDP to mixed member
parallel, but the newly introduced PR tier never shows up in the data. Germany,
in contrast, is coded PR and Plurality for the entire observation period.
In short, the PR and plurality indicators should be removed from the analysis.

```{r, results = "asis"}
mytbl <- cor(tillman[, institution_location])
colnames(mytbl) <- rownames(mytbl) <- c(
    "ENEP", "Disproprtionality", "PR", "Plurality", "Closeness"
)
stargazer::stargazer(mytbl, header = FALSE,
    title = "Correlation of Demeaned Institutional Controls",
    label = "tbl:CorrelationInstitutions"
)
```

The impact which pre-electoral coaltions have on turnout does depend noticeably
on the refined set of institutional controls. Effect estimates stay close to the
results reported above as can be seen from  Table \ref{tbl:ResultsRefinedInstitutions}.
Accordingly, the mere existance of PECs does not seem to matter, but PECs that
acquire a significant share of votes boost turnout by 1.38 percentage points. In
fact, each additional percentage point that PECs account for increases turnout by
0.02 percentage points. However, these seemingly robust results go along with
lower p-values than before. In line with extant research, the effective number of
parties has an ambivalent effect on turnout, disproportionality decreases it, and
so do non-competitive elections.

```{r, include = FALSE}
packs <- c("plm", "splines", "texreg")
missing <- which(!(packs %in% rownames(installed.packages())))
if (any(missing)) {
    cat("Installing missing packages: ", packs[missing], "\n")
    install.packages(packs[missing], dependencies = TRUE)
}
lapply(packs, library, character.only = TRUE, quietly = TRUE)

# Constants
panel_id <- c("country", "year2")
control <- paste(
    c("enep", "disprop", "closeness", "growth", "lnincome"), collapse = " + "
)
treatment <- c("pec1", "pec20", "vote_pec", "smallpec+largepec")
response <- "turnout"
yr_range <- as.numeric(min(tillman$year):max(tillman$year))
knots_num <- 3
knots_loc <- quantile(yr_range, probs = seq(0, 1, length.out = knots_num))
yr_spline_labs <- paste0(paste0("yr_spline", 1:(knots_num + 1)))

# Data objects
yr_splines <- bs(yr_range, knots = knots_loc[-c(1, knots_num)], degree = 3)
yr_splines <- cbind.data.frame(yr_splines, yr_range)
colnames(yr_splines) <- c(yr_spline_labs, "year")
data_to_fit <- left_join(tillman, yr_splines, by = "year")
# Throws a warning about different attributes, STATA import legacy
data_to_fit <- pdata.frame(data_to_fit, index = c("country", "year2"))
fitted_models <- list()

# refit models
for (i in 1:length(treatment)) {
    assign(
        "frm",
        paste0(response, " ~ ", paste(treatment[i], control,
            paste(yr_spline_labs, collapse = " + "), sep = " + ")
        )
    )
    fitted_models[[i]] <- plm(
        as.formula(frm), model = "within", data = data_to_fit
    )
}
bk_se <- lapply(fitted_models, vcovBK, cluster = c("group"))
bk_pval <- lapply(fitted_models,
    function(x){
        lmtest::coeftest(x, vcov = vcovBK(x, cluster = "group"))[, 4]
    }
)
```

```{r, results = "asis"}
texreg(fitted_models,
    digits = 2,
    override.se = lapply(bk_se, function(x){sqrt(diag(x))}),
    override.p = bk_pval,
    custom.coef.names = c("PEC", "Parties", "Disproportionality",
        "Closeness", "Economic Growth", "log(Income)", "Spline 1",
        "Spline 2", "Spline 3", "Spline 4",
        "PEC $>$ 20\\%", "Vote PEC", "Small PEC", "Large PEC"
    ),
    reorder.coef = c(1, 11, 12, 13, 14, 2:10),
    caption = "Results with Refined Institutions", caption.above = TRUE,
    label = "tbl:ResultsRefinedInstitutions",
    stars = c(0.001,  0.01, 0.05, 0.1)
)
rm(list = ls()[!(ls() %in% clean_workspace)])
```


\section{Bringing polarization back in}

So far, the formation of PECs does not boost turnout, but their strong showing
reliably does. Notwithstanding, this result strikes me as spurious at because
voting percentages are downstream from turnout. Citizens first go to vote and
only then comes the counting. Hence, voting percentages cannot be known before
turnout is fixed.  Hence, there is every reason to doubt the association
between turnout and PEC strength. Polarization of the party system constitutes
one potential confounder, and Table \ref{tbl:UnivariateSummaryPolarization}
shows the distribution of Dalton's Index in Tillman's data.

```{r, uniSumPolarization, results = "asis"}
mytbl <- apply(tillman[, c("polarization", "polarization_wi")], 2, summary)
tmp <- aggregate(polarization_bw ~ country, data = tillman, FUN = mean)
mytbl <- cbind(mytbl, summary(tmp[, 2]))
colnames(mytbl) <- c("Polarization", "Within", "Between")
stargazer::stargazer(mytbl, header = FALSE,
    title = "Univariate Summary of Polarization",
    label = "tbl:UnivariateSummaryPolarization"
)
```

The next figure explores the bivariate correlation of within-changes in turnout
and polarization at various levels of PEC strength. First, in striking contrast
to the established literature the graph does not imply any clear pattern of the
association between turnout and polarization. Increasing polarization seems to
depress turnout in Austria whereas it gets out the vote in France. At the same
time, several countries imply strong linearities as can be seen from the
wiggly\footnote{I'm told ``wiggly'' is a proper scientific term.} loess
smoothers in the United Kingdom, Israel and Portugal. Moreover, it is not clear
from the graph that increased polarization is associated with higher voting
percentages for pre-electoral coalition. If that was the case, all countries in
the data should behave like Denmark and Italy where there are stark
bifurcations between elections with and without strong PECs. More typically,
PECs populate the entire range of voting percentages at each level of
polarization. In short, polarization does not seem to confound Tillman's analysis.

\begin{figure}
\caption{Bivariate Association of Turnout and Polarization}
\label{fig:ScatterTurnoutPolarization}

```{r}
tmp <- tillman %>% mutate(country = "All")
pdta <- rbind.data.frame(tillman, tmp)
ggplot(data = pdta, aes(x = polarization_wi, turnout_wi)) +
    geom_point(aes(size = vote_pec)) + geom_smooth(se = FALSE, span = .9) +
    facet_wrap(vars(country)) +
    labs(x = "Demeaned Party System Polarization", y = "Demeaned Turnout",
        size = "PEC voting percentage"
    ) +
    theme(legend.position = "bottom", legend.direction = "horizontal")
rm(tmp, pdta)
```

\end{figure}

```{r, include = FALSE}
packs <- c("plm", "splines", "texreg")
missing <- which(!(packs %in% rownames(installed.packages())))
if (any(missing)) {
    cat("Installing missing packages: ", packs[missing], "\n")
    install.packages(packs[missing], dependencies = TRUE)
}
lapply(packs, library, character.only = TRUE, quietly = TRUE)

# Constants
panel_id <- c("country", "year2")
control <- paste(
    c("polarization", "enep", "disprop", "closeness", "growth", "lnincome"),
    collapse = " + "
)
treatment <- c("pec1", "pec20", "vote_pec", "smallpec+largepec")
response <- "turnout"
yr_range <- as.numeric(min(tillman$year):max(tillman$year))
knots_num <- 3
knots_loc <- quantile(yr_range, probs = seq(0, 1, length.out = knots_num))
yr_spline_labs <- paste0(paste0("yr_spline", 1:(knots_num + 1)))

# Data objects
yr_splines <- bs(yr_range, knots = knots_loc[-c(1, knots_num)], degree = 3)
yr_splines <- cbind.data.frame(yr_splines, yr_range)
colnames(yr_splines) <- c(yr_spline_labs, "year")
data_to_fit <- left_join(tillman, yr_splines, by = "year")
# Throws a warning about different attributes, STATA import legacy
data_to_fit <- pdata.frame(data_to_fit, index = c("country", "year2"))
fitted_models <- list()

# refit models
assign( # baseline
        "frm",
        paste0(response, " ~ ", paste(
            control, paste(yr_spline_labs, collapse = " + "), sep = " + "
        )
    )
)
fitted_models[[1]] <- plm(
    as.formula(frm), model = "within", data = data_to_fit
)
for (i in 1:length(treatment)) {
    assign(
        "frm",
        paste0(response, " ~ ", paste(treatment[i], control,
            paste(yr_spline_labs, collapse = " + "), sep = " + ")
        )
    )
    fitted_models[[i+1]] <- plm(
        as.formula(frm), model = "within", data = data_to_fit
    )
}
bk_se <- lapply(fitted_models, vcovBK, cluster = c("group"))
bk_pval <- lapply(fitted_models,
    function(x){
        lmtest::coeftest(x, vcov = vcovBK(x, cluster = "group"))[, 4]
    }
)
```

The results in Table \ref{tbl:ResultsPolarization} confirm those expectations.
Even though the estimated effect on polarization is consistently positive, it
never achieves statistical significance. This result might depend on the assumed
functional form or the measurement and wards closer scrutiny. More importantly,
strong pre-electoral coalitions continue to support turnout even after
controlling for polarization. In other words, polarization does not seem to
confound that robust, but nonetheless dubious association. However, note that
the estimated effect of polarization is effectively halved when the strength
rather than existence of PECs comes into play. Apparently, PECs strength
mediates some of the effect of polarization on turnout which strikes me as
intuitive.

```{r, results = "asis"}
texreg(fitted_models,
    digits = 2,
    override.se = lapply(bk_se, function(x){sqrt(diag(x))}),
    override.p = bk_pval,
    custom.coef.names = c("Polarization", "Parties", "Disproportionality",
        "Closeness", "Economic Growth", "log(Income)", "Spline 1",
        "Spline 2", "Spline 3", "Spline 4", "PEC",
        "PEC $>$ 20\\%", "Vote PEC", "Small PEC", "Large PEC"
    ),
    reorder.coef = c(11:15, 1:10),
    caption = "Results with Refined Institutions", caption.above = TRUE,
    label = "tbl:ResultsPolarization",
    stars = c(0.001,  0.01, 0.05, 0.1)
)
rm(list = ls()[!(ls() %in% clean_workspace)])
```

\section{Next steps}

Here is a shopping list of things I consider worthwhile.

\begin{enumerate}
    \item Measurement: Acquire and evaluate measurements of Polarization.
    \item Refinement: Given somewhat unexpected results on polarization closer
        model inspection is justified.
    \item Theory building: What types of PECs do contribute to government
        identifiability?
\end{enumerate}

